// This is an autogenerated file from Firebase Studio.
'use server';

/**
 * @fileOverview Simulates Gemini API responses using predefined JSON files to populate a threat model.
 *
 * - llmPoweredThreatModelSimulation - A function that simulates Gemini API responses to generate a threat model.
 * - LLMPoweredThreatModelSimulationInput - The input type for the llmPoweredThreatModelSimulation function.
 * - LLMPoweredThreatModelSimulationOutput - The return type for the llmPoweredThreatModelSimulation function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const LLMPoweredThreatModelSimulationInputSchema = z.object({
  systemDescription: z.string().describe('Description of the AI agent system.'),
  maestroLayer: z.string().describe('The MAESTRO layer to generate the threat model for.'),
});
export type LLMPoweredThreatModelSimulationInput = z.infer<
  typeof LLMPoweredThreatModelSimulationInputSchema
>;

const ThreatSchema = z.object({
  name: z.string().describe('The name of the threat.'),
  description: z.string().describe('A detailed description of the threat.'),
  risk: z.enum(['Low', 'Medium', 'High', 'Critical']).describe('The assessed risk level of the threat.'),
});

const LLMPoweredThreatModelSimulationOutputSchema = z.object({
    threatModel: z.array(ThreatSchema).describe('The generated threat model as an array of threat objects.'),
});

export type LLMPoweredThreatModelSimulationOutput = z.infer<
  typeof LLMPoweredThreatModelSimulationOutputSchema
>;

export async function llmPoweredThreatModelSimulation(
  input: LLMPoweredThreatModelSimulationInput
): Promise<LLMPoweredThreatModelSimulationOutput> {
  return llmPoweredThreatModelSimulationFlow(input);
}

const prompt = ai.definePrompt({
  name: 'llmPoweredThreatModelSimulationPrompt',
  input: {schema: LLMPoweredThreatModelSimulationInputSchema},
  output: {schema: LLMPoweredThreatModelSimulationOutputSchema},
  prompt: `You are an expert AI security analyst specializing in threat modeling for complex AI agent systems using the MAESTRO framework.

Your task is to analyze the provided system description and identify potential threats within the specified MAESTRO layer.

Generate a list of 2-3 detailed and specific threats. For each threat, provide a name, a comprehensive description, and assess its risk level (Low, Medium, High, or Critical).

System Description:
{{{systemDescription}}}

MAESTRO Layer to Analyze:
{{{maestroLayer}}}

Return the output as a JSON object containing a 'threatModel' array. Each object in the array should represent a single threat and have 'name', 'description', and 'risk' fields. Ensure your analysis is directly relevant to the provided system and layer.`,
});

const llmPoweredThreatModelSimulationFlow = ai.defineFlow(
  {
    name: 'llmPoweredThreatModelSimulationFlow',
    inputSchema: LLMPoweredThreatModelSimulationInputSchema,
    outputSchema: LLMPoweredThreatModelSimulationOutputSchema,
  },
  async (input) => {
    const { output } = await prompt(input);
    if (!output) {
      throw new Error("Failed to generate threat model from LLM.");
    }
    // The model now directly returns the object in the correct format.
    return output;
  }
);
